{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155a04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75452a0b",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "## Ivan Makaveev, 2MI0600203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38e3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./house-votes-84.data\"\n",
    "random.seed(1337)\n",
    "\n",
    "laplace_smoothing = 1\n",
    "use_gauss = True\n",
    "preprocess = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddde278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    dataset = []\n",
    "    with open(path, 'r') as file:\n",
    "        csv = reader(file)\n",
    "        for row in csv:\n",
    "            if row:\n",
    "                dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac14741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(dataset, label, attr_idx):\n",
    "    data = [record[attr_idx] for record in filter(lambda rec: rec[0] == label , dataset)]\n",
    "    return max(data, key = data.count)\n",
    "\n",
    "def fill_missing(dataset, missing = \"?\"):\n",
    "    return [[attribute if attribute != missing else get_mode(dataset, record[0] , idx) for idx, attribute in enumerate(record)] for record in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b80848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_continous(dataset, value_map):\n",
    "    return [[value_map[attribute] if attribute in value_map.keys() else attribute for attribute in record] for record in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b30160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(file_path)\n",
    "\n",
    "if(use_gauss):\n",
    "    dataset = transform_continous(dataset, {\"y\": 2, \"?\": 1, \"n\": 0})\n",
    "elif(preprocess):\n",
    "    dataset = fill_missing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cace0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, smoothing):\n",
    "        if smoothing < 0:\n",
    "            raise ValueError(\"Smoothing factor must be >= 0\")\n",
    "            \n",
    "        self.classes = set()\n",
    "        self.class_prob = dict()\n",
    "        self.feature_conditional_prob = dict()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def extract_classes(self, data_train):\n",
    "        return set([record[0] for record in data_train])\n",
    "\n",
    "    def extract_features(self, data_train):\n",
    "        return [set([record[featureId] for record in data_train]) for featureId in range(1, len(data_train[0]))]\n",
    "    \n",
    "    def train(self, data_train):\n",
    "        self.classes = self.extract_classes(data_train)\n",
    "        self.class_prob = dict()\n",
    "        self.feature_conditional_prob = dict()\n",
    "        \n",
    "        data_size = len(data_train)\n",
    "        cols_count = len(data_train[0]) - 1\n",
    "        feature_values = self.extract_features(data_train)\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_records_count = len([record for record in data_train if record[0] == class_name])\n",
    "            self.class_prob[class_name] = (class_records_count + self.smoothing) / (data_size + self.smoothing * len(self.classes))\n",
    "            \n",
    "            self.feature_conditional_prob[class_name] = list()\n",
    "            for feature_id in range(0, cols_count):\n",
    "                value_conditional_prob = dict()\n",
    "                for value in feature_values[feature_id]:\n",
    "                    value_records_count = len([record for record in data_train if record[0] == class_name and record[feature_id + 1] == value])\n",
    "                    value_conditional_prob[value] =  (value_records_count + self.smoothing) / (class_records_count + self.smoothing * len(feature_values[feature_id]))\n",
    "                self.feature_conditional_prob[class_name].append(value_conditional_prob)\n",
    "                \n",
    "    def predict(self, instance):\n",
    "        instance_probs = dict()\n",
    "        features = len(instance)\n",
    "        \n",
    "        probs = dict()\n",
    "        for class_name in self.classes:\n",
    "            class_conditional_prob = math.log(self.class_prob[class_name])\n",
    "            for feature_id in range(0, features):\n",
    "                class_conditional_prob += math.log(self.feature_conditional_prob[class_name][feature_id][instance[feature_id]])\n",
    "            probs[class_name] = class_conditional_prob\n",
    "        \n",
    "        return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d986001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mean(value_list):\n",
    "    return sum(value_list) / len(value_list)\n",
    "\n",
    "def evaluate_sd(value_list):\n",
    "    mean = evaluate_mean(value_list)\n",
    "    sd = 0\n",
    "    for val in value_list:\n",
    "        sd += (val - mean) * (val - mean)\n",
    "    sd /= len(value_list)\n",
    "    \n",
    "    return math.sqrt(sd)\n",
    "\n",
    "def gauss_probability(value, mean, sd):\n",
    "    return (1 / math.sqrt(2 * sd * sd * math.pi)) * math.pow(math.e, -(value - mean)*(value - mean)/(2*sd*sd))\n",
    "\n",
    "def log_gauss_probability(value, mean, sd):\n",
    "    return -math.log(sd) -0.5 * math.log(2 * math.pi) - (value - mean) * (value - mean) / (2 * sd * sd)\n",
    "\n",
    "class NaiveBayesClassifier_Gaussian:\n",
    "    def __init__(self, smoothing):\n",
    "        if smoothing < 0:\n",
    "            raise ValueError(\"Smoothing factor must be >= 0\")\n",
    "            \n",
    "        self.classes = set()\n",
    "        self.class_prob = dict()\n",
    "        self.feature_conditional_prob = dict()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def extract_classes(self, data_train):\n",
    "        return set([record[0] for record in data_train])\n",
    "    \n",
    "    def train(self, data_train):\n",
    "        self.classes = self.extract_classes(data_train)\n",
    "        self.class_prob = dict()\n",
    "        self.feature_conditional_prob = dict()\n",
    "        \n",
    "        data_size = len(data_train)\n",
    "        cols_count = len(data_train[0]) - 1\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_records_count = len([record for record in data_train if record[0] == class_name])\n",
    "            self.class_prob[class_name] = (class_records_count + self.smoothing) / (data_size + self.smoothing * len(self.classes))\n",
    "            \n",
    "            self.feature_conditional_prob[class_name] = list()\n",
    "            for feature_id in range(0, cols_count):\n",
    "                feature_values = [record[feature_id + 1] for record in data_train if record[0] == class_name]\n",
    "                feature_mean = evaluate_mean(feature_values)\n",
    "                feature_sd = evaluate_sd(feature_values)\n",
    "                self.feature_conditional_prob[class_name].append((feature_mean, max(feature_sd, 1e-9)))\n",
    "                \n",
    "    def predict(self, instance):\n",
    "        instance_probs = dict()\n",
    "        features = len(instance)\n",
    "        \n",
    "        probs = dict()\n",
    "        for class_name in self.classes:\n",
    "            class_conditional_prob = math.log(self.class_prob[class_name])\n",
    "            for feature_id in range(0, features):\n",
    "                feature_mean, feature_sd = self.feature_conditional_prob[class_name][feature_id]\n",
    "                class_conditional_prob += log_gauss_probability(instance[feature_id], feature_mean, feature_sd)\n",
    "            probs[class_name] = class_conditional_prob\n",
    "        \n",
    "        return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfb980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, test_percentage):\n",
    "    if(test_percentage > 100 or test_percentage < 0):\n",
    "        raise ValueError(\"Test percentage must be between 0 and 100\")\n",
    "    \n",
    "    random.shuffle(dataset)\n",
    "    classes = set([record[0] for record in dataset])\n",
    "    group_dataset = [[record for record in dataset if record[0] == class_name] for class_name in classes]\n",
    "    \n",
    "    train = list()\n",
    "    test = list()\n",
    "    for group in group_dataset:\n",
    "        test_count = len(group) // test_percentage\n",
    "        test.extend(group[0:test_count])\n",
    "        train.extend(group[test_count:])\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfec247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_accuracy(model, test_instances, test_labels):\n",
    "    correct = 0\n",
    "    for idx, instance in enumerate(test_instances):\n",
    "        correct += model.predict(instance) == test_labels[idx]\n",
    "    \n",
    "    return correct * 100 / len(test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84806ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_test_performance(model, data_test):\n",
    "    return evalute_accuracy(model, [record[1:] for record in data_test], [record[0] for record in data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c3e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_train_performance(model, data_train, folds_count = 10):\n",
    "    folds = list()\n",
    "    fold_size = len(data_train) // folds_count\n",
    "    for idx in range(0, folds_count - 1):\n",
    "        fold_test = data_train[fold_size * idx : fold_size * (idx + 1)]\n",
    "        fold_train = data_train[0:fold_size * idx] + data_train[fold_size * (idx + 1):]\n",
    "        folds.append((fold_train, fold_test))\n",
    "    \n",
    "    last_fold = (data_train[0:fold_size * (folds_count - 1)], data_train[fold_size * (folds_count-1):])\n",
    "    folds.append(last_fold)\n",
    "    \n",
    "    accuracies = list()\n",
    "    for fold in folds:\n",
    "        model.train(fold[0])\n",
    "        accuracies.append(evalute_test_performance(model, fold[1]))\n",
    "    \n",
    "    model.train(data_train)\n",
    "    return accuracies, evalute_accuracy(model, [record[1:] for record in data_train], [record[0] for record in data_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff862a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33aff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 94.44%\n",
      "\n",
      "10-fold Cross Validation:\n",
      "Fold 1: 92.68%\n",
      "Fold 2: 97.56%\n",
      "Fold 3: 92.68%\n",
      "Fold 4: 92.68%\n",
      "Fold 5: 95.12%\n",
      "Fold 6: 97.56%\n",
      "Fold 7: 92.68%\n",
      "Fold 8: 90.24%\n",
      "Fold 9: 90.24%\n",
      "Fold 10: 97.78%\n",
      "Mean: 93.92%\n",
      "SD: 2.76\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesClassifier(1)\n",
    "if(use_gauss):\n",
    "    model = NaiveBayesClassifier_Gaussian(1)\n",
    "\n",
    "cross_val_accuracies, train_result = evalute_train_performance(model, train)\n",
    "\n",
    "print(f\"Train set accuracy: {train_result:.2f}%\")\n",
    "print()\n",
    "\n",
    "print(\"10-fold Cross Validation:\")\n",
    "for idx, accuracy in enumerate(cross_val_accuracies):\n",
    "    print(f\"Fold {idx + 1}: {accuracy:.2f}%\")\n",
    "\n",
    "print(f\"Mean: {evaluate_mean(cross_val_accuracies):.2f}%\")\n",
    "print(f\"SD: {evaluate_sd(cross_val_accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94605676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 95.24%\n"
     ]
    }
   ],
   "source": [
    "test_result = evalute_test_performance(model, test)\n",
    "print(f\"Test set accuracy: {test_result:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
